# =========================================================
# eval_small_summary_all.py
# ƒê√°nh gi√° to√†n b·ªô m√¥ h√¨nh YOLOv12 trong runs/detect/
# Ch·ªâ t√≠nh metrics tr√™n ƒë·ªëi t∆∞·ª£ng nh·ªè h∆°n 50px
# Xu·∫•t:
#   1. metrics_small_summary.csv  (chi ti·∫øt t·ª´ng model)
#   2. metrics_small_overall.csv  (trung b√¨nh 4 model)
# =========================================================
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
from pathlib import Path
import json, csv, os, sys

# ==== C·∫§U H√åNH ====
GT_JSON   = "WAID/annotations/test.json"   # Ground truth COCO
ROOT_DIR  = Path("runs/detect")            # Th∆∞ m·ª•c ch·ª©a model
THRESH_PX = 50                             # Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc nh·ªè (px)
OUT_DETAIL = "metrics_small_summary.csv"   # K·∫øt qu·∫£ t·ª´ng model
OUT_MEAN   = "metrics_small_overall.csv"   # K·∫øt qu·∫£ trung b√¨nh

# ==== H√ÄM PH·ª§ ====
def bbox_is_small(bbox, thresh=50):
    w, h = bbox[2], bbox[3]
    return max(w, h) < thresh

def normalize_name(name: str):
    base = os.path.basename(name)
    root, _ = os.path.splitext(base)
    return root.lower()

def evaluate_small(pred_json_path: Path, coco_gt: COCO, small_img_ids: list[int]):
    """ƒê√°nh gi√° mAP, Precision, Recall cho small objects"""
    with open(pred_json_path, "r") as f:
        preds = json.load(f)

    # map file_name ‚Üí image_id t·ª´ GT
    name_to_id = {normalize_name(img["file_name"]): img["id"]
                  for img in coco_gt.dataset["images"]}

    # l·ªçc prediction tr√πng ID nh·ªè
    small_preds, miss_count = [], 0
    for p in preds:
        img_name_raw = str(p.get("image_id"))
        norm = normalize_name(img_name_raw)
        if norm in name_to_id:
            coco_id = name_to_id[norm]
            if coco_id in small_img_ids:
                p["image_id"] = coco_id
                small_preds.append(p)
        else:
            miss_count += 1

    if len(small_preds) == 0:
        print(f"‚ö†Ô∏è {pred_json_path.parent.name}: kh√¥ng c√≥ prediction h·ª£p l·ªá (<{THRESH_PX}px)")
        return None

    tmp_json = pred_json_path.parent / "predictions_small_tmp.json"
    with open(tmp_json, "w") as f:
        json.dump(small_preds, f)

    # ƒë√°nh gi√°
    coco_dt = coco_gt.loadRes(str(tmp_json))
    coco_eval = COCOeval(coco_gt, coco_dt, "bbox")
    coco_eval.params.imgIds = small_img_ids
    coco_eval.evaluate()
    coco_eval.accumulate()
    coco_eval.summarize()

    # l·∫•y c√°c ch·ªâ s·ªë small
    (
        mAP_all, mAP50, mAP75,
        AP_small, AP_medium, AP_large,
        AR_all, AR50, AR75,
        AR_small, AR_medium, AR_large
    ) = coco_eval.stats

    precision = AP_small
    recall = AR_small
    mAP = mAP_all

    return precision, recall, mAP


# ==== B·∫ÆT ƒê·∫¶U ====
print(f"üìÇ Ground truth: {GT_JSON}")
if not os.path.exists(GT_JSON):
    print("‚ùå Kh√¥ng t√¨m th·∫•y file ground truth.")
    sys.exit()

coco_gt = COCO(GT_JSON)

# l·ªçc ·∫£nh c√≥ v·∫≠t nh·ªè
small_img_ids = []
for img_id, anns in coco_gt.imgToAnns.items():
    for ann in anns:
        if bbox_is_small(ann["bbox"], THRESH_PX):
            small_img_ids.append(img_id)
            break
print(f"üîπ ·∫¢nh c√≥ v·∫≠t nh·ªè (<{THRESH_PX}px): {len(small_img_ids)}")

# t√¨m predictions.json
folders = [p for p in ROOT_DIR.iterdir() if p.is_dir()]
print(f"üîç Ph√°t hi·ªán {len(folders)} m√¥ h√¨nh trong {ROOT_DIR}")

results = []

# ---- ƒê√ÅNH GI√Å T·ª™NG MODEL ----
with open(OUT_DETAIL, "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["Model Name", "Folder Path", "Precision (AP_small)", "Recall (AR_small)", "mAP_small (COCO)"])

    for folder in folders:
        pred_json = folder / "predictions.json"
        if not pred_json.exists():
            print(f"‚è≠Ô∏è B·ªè qua {folder.name} (kh√¥ng c√≥ predictions.json)")
            continue

        print(f"\nüöÄ ƒêang ƒë√°nh gi√° model: {folder.name}")
        result = evaluate_small(pred_json, coco_gt, small_img_ids)
        if result is None:
            continue

        precision, recall, mAP = result
        writer.writerow([
            folder.name,
            str(folder),
            round(precision, 4),
            round(recall, 4),
            round(mAP, 4)
        ])
        results.append((precision, recall, mAP))

print(f"\n‚úÖ Ho√†n t·∫•t. File chi ti·∫øt: {OUT_DETAIL}")

# ---- T√çNH TRUNG B√åNH ----
if results:
    avg_precision = sum(r[0] for r in results) / len(results)
    avg_recall = sum(r[1] for r in results) / len(results)
    avg_map = sum(r[2] for r in results) / len(results)

    with open(OUT_MEAN, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["Avg Precision (AP_small)", "Avg Recall (AR_small)", "Avg mAP_small (COCO)", "Num Models"])
        writer.writerow([
            round(avg_precision, 4),
            round(avg_recall, 4),
            round(avg_map, 4),
            len(results)
        ])

    print(f"üìä Trung b√¨nh 4 m√¥ h√¨nh: Precision={avg_precision:.4f}, Recall={avg_recall:.4f}, mAP={avg_map:.4f}")
    print(f"‚úÖ ƒê√£ l∆∞u file trung b√¨nh t·∫°i: {OUT_MEAN}")
else:
    print("‚ùå Kh√¥ng c√≥ m√¥ h√¨nh h·ª£p l·ªá ƒë·ªÉ t√≠nh trung b√¨nh.")
